{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create EMBER 2018 Malware Dataset <br>\n",
    "This program converts the ember malware database to a json format for export.<br>\n",
    "Install the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/elastic/ember.git pandas lightgbm lief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ember then create the vectorized features and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ember\n",
    "\n",
    "ember.create_vectorized_features(\"../dataset/data/ember2018/\")\n",
    "ember.create_metadata(\"../dataset/data/ember2018/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read metadata and vectorized features into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = ember.read_metadata(\"../dataset/data/ember2018/\")\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ember.read_vectorized_features(\"../dataset/data/ember2018/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details of x and y element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of Elements: {len(X_train)+len(X_test)}\")\n",
    "print(f\"X_train: {X_train[0]}\")\n",
    "print(f\"Number of columns in X_train: {len(X_train[0])}\")\n",
    "print(f\"y_train: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the JSON version of the dataset to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_dataset(df, x, y, size):\n",
    "    data_list = []\n",
    "    columns = df.columns\n",
    "    for i in range(size):\n",
    "        obj = {}    \n",
    "        ele = df.iloc[i]\n",
    "        obj[\"x\"] = x[i]\n",
    "        obj[\"y\"] = y[i]\n",
    "        for col in columns:\n",
    "            if col == \"avclass\" and isinstance(ele[col], float):\n",
    "                obj[col] = str(ele[col])\n",
    "            else:\n",
    "                obj[col] = ele[col]\n",
    "        data_list.append(obj)\n",
    "    return {\"data\":data_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sha256      0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...\n",
      "appeared                                              2006-12\n",
      "label                                                       0\n",
      "avclass                                                   NaN\n",
      "subset                                                  train\n",
      "Name: 0, dtype: object sha256      163ced46c18ef09d8e2f0ee4b16decf74a533f22ba3b59...\n",
      "appeared                                              2018-11\n",
      "label                                                       1\n",
      "avclass                                                 xtrat\n",
      "subset                                                   test\n",
      "Name: 800000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_df = metadata_df[metadata_df[\"subset\"]==\"train\"]\n",
    "test_df = metadata_df[metadata_df[\"subset\"]==\"test\"]\n",
    "\n",
    "print(train_df.iloc[0], test_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 800000\n",
    "num_test = 200000\n",
    "\n",
    "train_ds = get_dataset(train_df, X_train, y_train, num_train)\n",
    "test_ds = get_dataset(test_df, X_test, y_test, num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class JsonEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.float32):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(JsonEncoder, self).default(obj)\n",
    "\n",
    "def write_list(file_path, obj):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(obj, f, cls=JsonEncoder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Created.\n"
     ]
    }
   ],
   "source": [
    "train_output_path = \"../dataset/data/ember2018_train.json\"\n",
    "test_output_path = \"../dataset/data/ember2018_test.json\"\n",
    "\n",
    "write_list(train_output_path, train_ds)\n",
    "write_list(test_output_path, test_ds)\n",
    "print(\"Dataset Created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
