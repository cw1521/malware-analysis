{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create EMBER 2018 Malware Dataset <br>\n",
    "This program converts the ember malware database to a json format for export.<br>\n",
    "Install the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/elastic/ember.git\n",
      "  Cloning https://github.com/elastic/ember.git to c:\\users\\school\\appdata\\local\\temp\\pip-req-build-ty7i0w0l\n",
      "  Resolved https://github.com/elastic/ember.git to commit d97a0b523de02f3fe5ea6089d080abacab6ee931\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas in c:\\users\\school\\appdata\\local\\rlbotguix\\python37\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\school\\appdata\\local\\rlbotguix\\python37\\lib\\site-packages (3.3.5)\n",
      "Requirement already satisfied: lief in c:\\users\\school\\appdata\\local\\rlbotguix\\python37\\lib\\site-packages (0.12.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\school\\appdata\\local\\rlbotguix\\python37\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\school\\appdata\\local\\rlbotguix\\python37\\lib\\site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\school\\appdata\\roaming\\python\\python37\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\school\\appdata\\local\\rlbotguix\\python37\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\school\\appdata\\local\\rlbotguix\\python37\\lib\\site-packages (from lightgbm) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\school\\appdata\\local\\rlbotguix\\python37\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\school\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\school\\appdata\\local\\rlbotguix\\python37\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\school\\appdata\\local\\rlbotguix\\python37\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/elastic/ember.git 'C:\\Users\\school\\AppData\\Local\\Temp\\pip-req-build-ty7i0w0l'\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/elastic/ember.git pandas lightgbm lief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ember then create the vectorized features and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ember\n",
    "\n",
    "# ember.create_vectorized_features(\"../dataset/data/ember2018/\")\n",
    "# ember.create_metadata(\"../dataset/data/ember2018/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read metadata and vectorized features into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha256</th>\n",
       "      <th>appeared</th>\n",
       "      <th>label</th>\n",
       "      <th>avclass</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
       "      <td>2006-12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
       "      <td>2007-01</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eac8ddb4970f8af985742973d6f0e06902d42a3684d791...</td>\n",
       "      <td>2007-02</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f513818bcc276c531af2e641c597744da807e21cc1160...</td>\n",
       "      <td>2007-02</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...</td>\n",
       "      <td>2007-02</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>e033bc4967ce64bbb5cafdb234372099395185a6e0280c...</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>1</td>\n",
       "      <td>zbot</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>c7d16736fd905f5fbe4530670b1fe787eb12ee86536380...</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>1</td>\n",
       "      <td>flystudio</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0020077cb673729209d88b603bddf56b925b18e682892a...</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1b7e7c8febabf70d1c17fe3c7abf80f33003581c380f28...</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>836063f2312b597632bca1f738e68e4d23f672d587a7fc...</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>1</td>\n",
       "      <td>emotet</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   sha256 appeared  label  \\\n",
       "0       0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...  2006-12      0   \n",
       "1       c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...  2007-01      0   \n",
       "2       eac8ddb4970f8af985742973d6f0e06902d42a3684d791...  2007-02      0   \n",
       "3       7f513818bcc276c531af2e641c597744da807e21cc1160...  2007-02      0   \n",
       "4       ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...  2007-02      0   \n",
       "...                                                   ...      ...    ...   \n",
       "999995  e033bc4967ce64bbb5cafdb234372099395185a6e0280c...  2018-12      1   \n",
       "999996  c7d16736fd905f5fbe4530670b1fe787eb12ee86536380...  2018-12      1   \n",
       "999997  0020077cb673729209d88b603bddf56b925b18e682892a...  2018-12      0   \n",
       "999998  1b7e7c8febabf70d1c17fe3c7abf80f33003581c380f28...  2018-12      0   \n",
       "999999  836063f2312b597632bca1f738e68e4d23f672d587a7fc...  2018-12      1   \n",
       "\n",
       "          avclass subset  \n",
       "0             NaN  train  \n",
       "1             NaN  train  \n",
       "2             NaN  train  \n",
       "3             NaN  train  \n",
       "4             NaN  train  \n",
       "...           ...    ...  \n",
       "999995       zbot   test  \n",
       "999996  flystudio   test  \n",
       "999997        NaN   test  \n",
       "999998        NaN   test  \n",
       "999999     emotet   test  \n",
       "\n",
       "[1000000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = ember.read_metadata(\"../dataset/data/ember2018/\")\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
      "WARNING:   lief version 0.12.3-39115d10 found instead. There may be slight inconsistencies\n",
      "WARNING:   in the feature calculations.\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = ember.read_vectorized_features(\"../dataset/data/ember2018/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details of x and y element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Elements: 1000000\n",
      "X_train: [0.01467612 0.00422187 0.00392268 ... 0.         0.         0.        ]\n",
      "Number of columns in X_train: 2381\n",
      "y_train: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Elements: {len(X_train)+len(X_test)}\")\n",
    "print(f\"X_train: {X_train[0]}\")\n",
    "print(f\"Number of columns in X_train: {len(X_train[0])}\")\n",
    "print(f\"y_train: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the JSON version of the dataset to export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_data(df, x, y, size):\n",
    "    data_list = []\n",
    "    columns = df.columns\n",
    "    for i in range(size):\n",
    "        if i % 10000 == 0:\n",
    "            print (f\"Element: {i}\")\n",
    "        obj = {}    \n",
    "        ele = df.iloc[i]\n",
    "        obj[\"x\"] = x[i]\n",
    "        obj[\"y\"] = y[i]\n",
    "        for col in columns:\n",
    "            if col == \"avclass\" and isinstance(ele[col], float):\n",
    "                obj[col] = str(ele[col])\n",
    "            elif col == \"label\":\n",
    "                obj[col] = str(ele[col])\n",
    "            else:\n",
    "                obj[col] = ele[col]\n",
    "        data_list.append(obj)\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sha256      0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...\n",
      "appeared                                              2006-12\n",
      "label                                                       0\n",
      "avclass                                                   NaN\n",
      "subset                                                  train\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_df = metadata_df[metadata_df[\"subset\"]==\"train\"]\n",
    "test_df = metadata_df[metadata_df[\"subset\"]==\"test\"]\n",
    "\n",
    "print(train_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element: 0\n",
      "Element: 10000\n",
      "Element: 20000\n",
      "Element: 30000\n",
      "Element: 40000\n",
      "Element: 50000\n",
      "Element: 60000\n",
      "Element: 70000\n",
      "Element: 80000\n",
      "Element: 90000\n",
      "Element: 100000\n",
      "Element: 110000\n",
      "Element: 120000\n",
      "Element: 130000\n",
      "Element: 140000\n",
      "Element: 150000\n",
      "Element: 160000\n",
      "Element: 170000\n",
      "Element: 180000\n",
      "Element: 190000\n",
      "Element: 200000\n",
      "Element: 210000\n",
      "Element: 220000\n",
      "Element: 230000\n",
      "Element: 240000\n",
      "Element: 250000\n",
      "Element: 260000\n",
      "Element: 270000\n",
      "Element: 280000\n",
      "Element: 290000\n",
      "Element: 300000\n",
      "Element: 310000\n",
      "Element: 320000\n",
      "Element: 330000\n",
      "Element: 340000\n",
      "Element: 350000\n",
      "Element: 360000\n",
      "Element: 370000\n",
      "Element: 380000\n",
      "Element: 390000\n",
      "Element: 400000\n",
      "Element: 410000\n",
      "Element: 420000\n",
      "Element: 430000\n",
      "Element: 440000\n",
      "Element: 450000\n",
      "Element: 460000\n",
      "Element: 470000\n",
      "Element: 480000\n",
      "Element: 490000\n",
      "Element: 500000\n",
      "Element: 510000\n",
      "Element: 520000\n",
      "Element: 530000\n",
      "Element: 540000\n",
      "Element: 550000\n",
      "Element: 560000\n",
      "Element: 570000\n",
      "Element: 580000\n",
      "Element: 590000\n",
      "Element: 600000\n",
      "Element: 610000\n",
      "Element: 620000\n",
      "Element: 630000\n",
      "Element: 640000\n",
      "Element: 650000\n",
      "Element: 660000\n",
      "Element: 670000\n",
      "Element: 680000\n",
      "Element: 690000\n",
      "Element: 700000\n",
      "Element: 710000\n",
      "Element: 720000\n",
      "Element: 730000\n",
      "Element: 740000\n",
      "Element: 750000\n",
      "Element: 760000\n",
      "Element: 770000\n",
      "Element: 780000\n",
      "Element: 790000\n",
      "Element: 0\n",
      "Element: 10000\n",
      "Element: 20000\n",
      "Element: 30000\n",
      "Element: 40000\n",
      "Element: 50000\n",
      "Element: 60000\n",
      "Element: 70000\n",
      "Element: 80000\n",
      "Element: 90000\n",
      "Element: 100000\n",
      "Element: 110000\n",
      "Element: 120000\n",
      "Element: 130000\n",
      "Element: 140000\n",
      "Element: 150000\n",
      "Element: 160000\n",
      "Element: 170000\n",
      "Element: 180000\n",
      "Element: 190000\n"
     ]
    }
   ],
   "source": [
    "num_train = 800000\n",
    "num_test = 200000\n",
    "\n",
    "train_ds = get_data(train_df, X_train, y_train, num_train)\n",
    "test_ds = get_data(test_df, X_test, y_test, num_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def write_file(list, num_files, num_elements, task):\n",
    "    output = {\"test\": \"test\"}\n",
    "    file_size = num_elements // num_files\n",
    "    file_number = 1\n",
    "    for i in range(0, num_elements, file_size):\n",
    "        output_path = f\"{os.getcwd()}\\\\data\\\\output\\\\{file_number}.json\"\n",
    "        if len(list[i:]) == file_size:\n",
    "            output = list[i:file_size+i]\n",
    "        else:\n",
    "            output = list[i:]\n",
    "        print(f\"Writing File: {output_path}\")\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            pickle.dump(output, f)\n",
    "        file_number += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing File: c:\\Users\\school\\code\\malware-analysis\\dataset\\data\\output\\1.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14032\\2209149141.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwrite_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mwrite_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dataset Created.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14032\\1083753488.py\u001b[0m in \u001b[0;36mwrite_file\u001b[1;34m(list, num_files, num_elements, task)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Writing File: {output_path}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mfile_number\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "write_file(train_ds, 10, num_train, \"train\")\n",
    "write_file(test_ds, 10, num_test, \"test\")\n",
    "\n",
    "print(\"Dataset Created.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
