import jsonlines
from os import getcwd, path, makedirs
from multiprocessing import Pool, cpu_count
import numpy as np
import sys



def get_data(df, x, y, size):
    div_len = 10000
    data_list = divide_data_to_list(df, x, y, div_len, size)
    results_list = job(get_obj_list, data_list)
    data = [data for result in results_list for data in result]
    
    return data


def get_num_procs():
    # mod = cpu_count()//2
    num_proc = cpu_count() // 4
    return num_proc


def divide_data_to_list(df, x, y, div_len, size):
    data_list = []
    for i in range(0, size, div_len):
        if size - i >= div_len:
            data = {
                "df": df.iloc[i:i+div_len],
                "x": x[i:i+div_len],
                "y": y[i:i+div_len]
            }
            data_list.append(data)
        else:
            data = {
                "df": df.iloc[i:i+div_len],
                "x": x[i:i+div_len],
                "y": y[i:i+div_len]
            }
            data_list.append(data)
    return data_list


def get_obj_list(data_list):
    obj_list = []
    columns = data_list["df"].columns
    for i in range(len(data_list["x"])):
        obj = get_obj(
            data_list["df"].iloc[i],
            data_list["x"][i],
            data_list["y"][i],
            columns
        )
        obj_list.append(obj)
    return obj_list


def get_obj(ele, x, y, columns):
    obj = {}    
    xi = " ".join(str(j) for j in x)
    obj["x"] = x.tolist()
    obj["input"] = xi
    obj["y"] = float(y)
    for col in columns:
        if not isinstance(ele[col], str):
            obj[col] = str(ele[col])
        else:
            obj[col] = ele[col]
    return obj


def job(f, args_list):
    num_proc = get_num_procs()
    results_list = []
    with Pool(num_proc) as p:
        results_list = p.map(f, args_list)
    return results_list


def write_ds(ilist, num_div, task):
    file_list = get_file_list(ilist, num_div, task)
    write_output_list(file_list)


def write_output_list(output_list):
    for output in output_list:
        print(f"Writing file: {output[0]}")
        with jsonlines.open(output[0], "w") as writer:
            writer.write_all(output[1])


def get_file_list(ilist, num_div, task):
    file_list = []
    div_len = len(ilist) // num_div
    file_number = 0
    for i in range(0, len(ilist), div_len):
        ofile = []
        file_number += 1
        output_path = f"{getcwd()}\\dataset\\data\\output\\ember2018_{task}_{file_number}.jsonl"
        if len(ilist) - i >= div_len:
            ofile = [output_path, ilist[i:div_len+i]]
        else:
            ofile = [output_path, ilist[i:]]
        file_list.append(ofile)
    return file_list


def create_and_output_dataset(num_file_div, ds_type):
    df, x, y = get_raw_dataset_by_type(ds_type)
    num_records = len(x)
    print(f"Creating the '{ds_type}' dataset.")
    ds = get_data(df, x, y, num_records)
    print(f"Dataset '{ds_type}' containing {len(ds)} records created.")
    print(f"Writing the '{ds_type}' dataset to disk.")
    write_ds(ds, num_file_div, ds_type)
    print(f"Dataset '{ds_type}' written to disk.")


def get_raw_data():
    import ember
    metadata_df = ember.read_metadata("../data/ember2018/")
    X_train, y_train, X_test, y_test = ember.read_vectorized_features("../data/ember2018/")
    return metadata_df, X_train, y_train, X_test, y_test


def get_raw_dataset_by_type(ds_type):
    metadata_df, X_train, y_train, X_test, y_test = get_raw_data()
    if ds_type == "train":
        train_df = metadata_df[metadata_df["subset"]=="train"]
        return train_df, X_train, y_train
    elif ds_type == "test":
        test_df = metadata_df[metadata_df["subset"]=="test"]
        return test_df, X_test, y_test
    else:
        num_records = 10000
        test_df = metadata_df[metadata_df["subset"]=="test"]
        return test_df[0:num_records], X_test[0:num_records], y_test[0:num_records]


def run_test():
    test_file_div = 20
    ds_type = ""
    print("\nRunning Test Mode.")
    create_and_output_dataset(test_file_div, ds_type)
        


        

def main():
    output_dir = f"{getcwd()}\\dataset\\data\\output"
    test = False

    if len(sys.argv) > 1:
        if sys.argv[1] == "test":
            test = True

    train_file_div = 400
    train_type = "train"

    test_file_div = 100
    test_type = "test"

    if not path.exists(output_dir):
        makedirs(output_dir)

    if not test:
        print(f"\nThis program creates and then writes the '{train_type}' and '{test_type}' datasets to file.")
        create_and_output_dataset(train_file_div, train_type)
        create_and_output_dataset(test_file_div, test_type)
    else:
        run_test()
        




if __name__ == "__main__":
    main()