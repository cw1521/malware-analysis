import json
import os


# Create the JSON version of the dataset to export

def get_data(df, x, y, size):
    data_list = []
    columns = df.columns
    for i in range(size):
        if i % 10000 == 0:
            print (f"Element: {i}")
        obj = {}    
        ele = df.iloc[i]
        obj["x"] = x[i]
        obj["y"] = y[i]
        for col in columns:
            if col == "avclass" and isinstance(ele[col], float):
                obj[col] = str(ele[col])
            elif col == "label":
                obj[col] = str(ele[col])
            else:
                obj[col] = ele[col]
        data_list.append(obj)
    return data_list


def split_list(ilist, num_div, task):
    olist = []
    div_size = len(ilist) // num_div
    file_number = 0
    for i in range(0, len(ilist), div_size):
        file_number += 1
        if len(ilist[i:div_size+i]) == div_size:
            olist.append((ilist[i:div_size+i], file_number, task))
        else:
            olist.append((ilist[i:], file_number, task))
    return olist



class NumpyEncoder(json.JSONEncoder):
    """ Special json encoder for numpy types """
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)


def write_list(ilist):
    output_path = f"{os.getcwd()}\\dataset\\data\\output\\ember2018_{str(ilist[2])}_{str(ilist[1])}.json"
    print(f"Writing File: {ilist[1]}")
    with open(output_path, "w") as f:            
        json.dump(ilist[0], f, cls=NumpyEncoder)


def write_files(file_list):
    for file in file_list:
        write_list(file)



if __name__ == "__main__":
    # Import ember then create the vectorized features and metadata

    import ember
    import numpy as np

    # Uncomment if metadata or vectors arent created
    # ember.create_vectorized_features("../data/ember2018/")
    # ember.create_metadata("../data/ember2018/")



    metadata_df = ember.read_metadata("../data/ember2018/")

    X_train, y_train, X_test, y_test = ember.read_vectorized_features("../data/ember2018/")






    train_df = metadata_df[metadata_df["subset"]=="train"]
    test_df = metadata_df[metadata_df["subset"]=="test"]

    num_train = 800000
    num_test = 200000




    train_ds = get_data(train_df, X_train, y_train, num_train)
    test_ds = get_data(test_df, X_test, y_test, num_test)



    train_split = split_list(train_ds, 80, "train")
    test_split = split_list(test_ds, 20, "test")



    # write_files(train_split)
    write_files(test_split)

    print("Dataset Created.")