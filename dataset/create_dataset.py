import jsonlines
from os import getcwd, path, makedirs
from multiprocessing import Pool, cpu_count
import numpy as np
import sys



def get_data(df, x, y, size):
    div_len = 10000
    data_list = divide_data_to_list(df, x, y, div_len, size)
    results_list = job(get_obj_list, data_list)
    data = [data for result in results_list for data in result]
    return data


def get_num_procs():
    mod = cpu_count() // 4
    num_proc = cpu_count() - mod
    return num_proc


def divide_data_to_list(df, x, y, div_len, size):
    data_list = []
    for i in range(0, size, div_len):
        if size - i >= div_len:
            data = {
                "df": df.iloc[i:i+div_len],
                "x": x[i:i+div_len],
                "y": y[i:i+div_len]
            }
            data_list.append(data)
        else:
            data = {
                "df": df.iloc[i:i+div_len],
                "x": x[i:i+div_len],
                "y": y[i:i+div_len]
            }
            data_list.append(data)
    return data_list


def get_obj_list(data_list):
    obj_list = []
    columns = data_list["df"].columns
    for i in range(len(data_list["x"])):
        obj = get_obj(
            data_list["df"].iloc[i],
            data_list["x"][i],
            data_list["y"][i],
            columns
        )
        obj_list.append(obj)
    return obj_list


def get_obj(ele, x, y, columns):
    obj = {}    
    xi = " ".join(str(j) for j in x)
    obj["x"] = x.tolist()
    obj["input"] = xi
    obj["y"] = str(y)
    for col in columns:
        if not isinstance(ele[col], str):
            obj[col] = str(ele[col])
        else:
            obj[col] = ele[col]
    return obj


def job(f, args_list):
    num_proc = get_num_procs()
    results_list = []
    with Pool(num_proc) as p:
        results_list = p.map(f, args_list)
    return results_list


def write_ds(ilist, num_div, task):
    file_list = get_file_list(ilist, num_div, task)
    write_output_list(file_list)


def write_output_list(output_list):
    for output in output_list:
        print(f"Writing file: {output[0]}")
        with jsonlines.open(output[0], "w") as writer:
            writer.write_all(output[1])


def get_file_list(ilist, num_div, task):
    file_list = []
    div_len = len(ilist) // num_div
    file_number = 0
    for i in range(0, len(ilist), div_len):
        ofile = []
        file_number += 1
        output_path = f"{getcwd()}\\dataset\\data\\output\\ember2018_{task}_{file_number}.jsonl"
        if len(ilist) - i >= div_len:
            ofile = [output_path, ilist[i:div_len+i]]
        else:
            ofile = [output_path, ilist[i:]]
        file_list.append(ofile)
    return file_list



    

def main():
    import ember

    output_dir = f"{getcwd()}\\dataset\\data\\output"


    test = False

    if len(sys.argv) > 1:
        if sys.argv[1] == "test":
            test = True

    # Uncomment if metadata or vectors arent created
    # ember.create_vectorized_features("../data/ember2018/")
    # ember.create_metadata("../data/ember2018/")

    metadata_df = ember.read_metadata("../data/ember2018/")

    X_train, y_train, X_test, y_test = ember.read_vectorized_features("../data/ember2018/")

    train_df = metadata_df[metadata_df["subset"]=="train"]
    test_df = metadata_df[metadata_df["subset"]=="test"]

    num_train = len(X_train)
    num_test = len(X_test)

    train_file_div = 1000
    train_type = "train"

    test_file_div = 200
    test_type = "test"

    if not path.exists(output_dir):
        makedirs(output_dir)

    # print(test_ds[0])

    if not test:

        print("\nCreating the 'train' and 'test' split of the dataset.")
        train_ds = get_data(train_df, X_train, y_train, num_train)
        # print(train_ds[0])
        print(f"'Train' dataset created.\nNumber of records: {len(train_ds)}.\nCreating the 'test' dataset.")

        test_ds = get_data(test_df, X_test, y_test, num_test)
        # print(test_ds[0])
        print(f"'Test' dataset created.\nNumber of records: {len(test_ds)}")

        print("Serializing and writing the 'train' dataset to disk.")
        write_ds(train_ds, train_file_div, train_type)

        print("Serializing and writing the 'test' dataset to disk.")
        write_ds(test_ds, test_file_div, test_type)

        print("Datasets Created.")


    else:
        num_test = 10000
        print("\nCreating the 'test' split of the dataset.")
        test_ds = get_data(test_df.iloc[0:10000], X_test[0:10000], y_test[0:10000], num_test)
        # print(test_ds[0])
        print(f"'Test' dataset created.\nNumber of records: {len(test_ds)}")

        ans = input("Write files? Type 'y' to continue\n>> ")

        if ans.lower() == "y" or ans.lower() == "yes":

            print("Serializing and writing the 'test' dataset to disk.")
            write_ds(test_ds, test_file_div, test_type)

            print("Datasets Created.")













if __name__ == "__main__":
    main()